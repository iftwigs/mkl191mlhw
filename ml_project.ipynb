{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from collections import defaultdict, Counter\n",
    "from string import punctuation\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.cluster import MeanShift, DBSCAN\n",
    "from sklearn.decomposition import PCA, TruncatedSVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Описательный анализ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для этой части выбрала пункт за 1.75 балла (Описательный анализ тестовой выборки в сравнение с обучающей - какие языки представлены, как они по статистикам отличаются от трейна)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic_full = pd.read_csv('jigsaw-toxic-comment-train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic = toxic_full.sample(frac=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>202401</th>\n",
       "      <td>aac04d8feb3e4b39</td>\n",
       "      <td>\" \\n :Left more detail under the review at Tal...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84162</th>\n",
       "      <td>e12a43cefe51d6fe</td>\n",
       "      <td>\"\\n\\nSpeedy deletion of \"\"Shrini\"\"\\n A page yo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62253</th>\n",
       "      <td>a6956e341824c2b4</td>\n",
       "      <td>)\\na cowards site, that must stop changing thi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113431</th>\n",
       "      <td>5e98a73ecce25fcd</td>\n",
       "      <td>Arg. \\n\\nTHis shit is not CREDIBLE!</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56104</th>\n",
       "      <td>95ebdc00350058cb</td>\n",
       "      <td>dhdhhdfh \\n\\ndeleting an account isnt going to...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75437</th>\n",
       "      <td>c9cf6a055dfac6ee</td>\n",
       "      <td>\"\\n Comment redacted. We'll all be reduced to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137334</th>\n",
       "      <td>dece133d021adb75</td>\n",
       "      <td>\"\\n\\n The borders of the new state were not sp...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59050</th>\n",
       "      <td>9e2545dd971e7ed0</td>\n",
       "      <td>}}\\n{{Old AfD multi|page=Wee Shu Min elitism c...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60829</th>\n",
       "      <td>a2d9eab4c472e2cb</td>\n",
       "      <td>Of course, it's an OR review of mine, just to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107437</th>\n",
       "      <td>3e571977469fe055</td>\n",
       "      <td>I don't give a damn about religion, but it's o...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                       comment_text  \\\n",
       "202401  aac04d8feb3e4b39  \" \\n :Left more detail under the review at Tal...   \n",
       "84162   e12a43cefe51d6fe  \"\\n\\nSpeedy deletion of \"\"Shrini\"\"\\n A page yo...   \n",
       "62253   a6956e341824c2b4  )\\na cowards site, that must stop changing thi...   \n",
       "113431  5e98a73ecce25fcd                Arg. \\n\\nTHis shit is not CREDIBLE!   \n",
       "56104   95ebdc00350058cb  dhdhhdfh \\n\\ndeleting an account isnt going to...   \n",
       "75437   c9cf6a055dfac6ee  \"\\n Comment redacted. We'll all be reduced to ...   \n",
       "137334  dece133d021adb75  \"\\n\\n The borders of the new state were not sp...   \n",
       "59050   9e2545dd971e7ed0  }}\\n{{Old AfD multi|page=Wee Shu Min elitism c...   \n",
       "60829   a2d9eab4c472e2cb  Of course, it's an OR review of mine, just to ...   \n",
       "107437  3e571977469fe055  I don't give a damn about religion, but it's o...   \n",
       "\n",
       "        toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
       "202401      0             0        0       0       0              0  \n",
       "84162       0             0        0       0       0              0  \n",
       "62253       1             0        1       0       0              0  \n",
       "113431      1             0        1       0       0              0  \n",
       "56104       0             0        0       0       0              0  \n",
       "75437       0             0        0       0       0              0  \n",
       "137334      0             0        0       0       0              0  \n",
       "59050       0             0        0       0       0              0  \n",
       "60829       0             0        0       0       0              0  \n",
       "107437      1             0        0       0       0              0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>content</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Doctor Who adlı viki başlığına 12. doctor olar...</td>\n",
       "      <td>tr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Вполне возможно, но я пока не вижу необходимо...</td>\n",
       "      <td>ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Quindi tu sei uno di quelli   conservativi  , ...</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Malesef gerçekleştirilmedi ancak şöyle bir şey...</td>\n",
       "      <td>tr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>:Resim:Seldabagcan.jpg resminde kaynak sorunu ...</td>\n",
       "      <td>tr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Le truc le plus important dans ta tirade c est...</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>20px Caro editor, encontramos problemas na edi...</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>el skate es unos de los deportes favoritos de ...</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Me doy la bienvenida. A este usuari le gusta c...</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>ES NOTABLEMENTE TENDENCIOSO, NO SE HABLA DE CU...</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            content lang\n",
       "0   0  Doctor Who adlı viki başlığına 12. doctor olar...   tr\n",
       "1   1   Вполне возможно, но я пока не вижу необходимо...   ru\n",
       "2   2  Quindi tu sei uno di quelli   conservativi  , ...   it\n",
       "3   3  Malesef gerçekleştirilmedi ancak şöyle bir şey...   tr\n",
       "4   4  :Resim:Seldabagcan.jpg resminde kaynak sorunu ...   tr\n",
       "5   5  Le truc le plus important dans ta tirade c est...   fr\n",
       "6   6  20px Caro editor, encontramos problemas na edi...   pt\n",
       "7   7  el skate es unos de los deportes favoritos de ...   es\n",
       "8   8  Me doy la bienvenida. A este usuari le gusta c...   es\n",
       "9   9  ES NOTABLEMENTE TENDENCIOSO, NO SE HABLA DE CU...   es"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic_test.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем статистики."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words_count(text):\n",
    "    text = word_tokenize(text)\n",
    "    text = [word.strip(punctuation) for word in text]\n",
    "    text = [word for word in text if word != '']\n",
    "    return len(text)\n",
    "        \n",
    "def sents_count(text):\n",
    "    text = sent_tokenize(text)\n",
    "    return len(text)\n",
    "    \n",
    "def chars_count(text):\n",
    "    chars = [x for x in text if x not in punctuation]\n",
    "    return len(chars)\n",
    "    \n",
    "def mean_word_length(text):\n",
    "    text = word_tokenize(text)\n",
    "    text = [word.strip(punctuation) for word in text]\n",
    "    text = [word for word in text if word != '']\n",
    "    lens = [len(x) for x in text]\n",
    "    return round(np.mean(lens), 2)\n",
    "    \n",
    "def mean_sent_length(text):\n",
    "    text = sent_tokenize(text)\n",
    "    lens = [len(word_tokenize(s)) for s in text]\n",
    "    return round(np.mean(lens), 2)\n",
    "\n",
    "def caps_percentage(text):\n",
    "    text_len = chars_count(text)\n",
    "    caps = 0\n",
    "    for l in text:\n",
    "        if l != ' ' and l not in punctuation:\n",
    "            if l != l.lower():\n",
    "                caps += 1\n",
    "    if text_len > 0:\n",
    "        return round(caps / text_len * 100, 2)\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def punctuation_percentage(text):\n",
    "    text_len = chars_count(text)\n",
    "    punc = 0\n",
    "    for l in text:\n",
    "        if l in punctuation:\n",
    "            punc += 1\n",
    "    if text_len > 0:    \n",
    "        return round(punc / text_len * 100, 2)\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def word_repeat_ratio(text):\n",
    "    text = word_tokenize(text)\n",
    "    text = [word.strip(punctuation) for word in text]\n",
    "    words = []\n",
    "    repetitions = []\n",
    "    for word in text:\n",
    "        if word not in words:\n",
    "            words.append(word)\n",
    "        else:\n",
    "            if word not in repetitions:\n",
    "                repetitions.append(word)\n",
    "    if len(words) > 0:\n",
    "        return round(len(repetitions) / len(words) * 100, 2)\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def character_repeat(text):\n",
    "    text = word_tokenize(text)\n",
    "    text = [word.strip(punctuation) for word in text]\n",
    "    text = [word for word in text if word != '']\n",
    "    words_with_repetitions = 0\n",
    "    for word in text:\n",
    "        res = re.findall(r'(\\w)\\1+', word)\n",
    "        if res != []:\n",
    "            words_with_repetitions += 1\n",
    "    if len(text) > 0:\n",
    "        return round(words_with_repetitions / len(text) * 100, 2)\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def punctuation_repeat(text):\n",
    "    res = re.findall(\"[?!.]+\", text)\n",
    "    length = 0\n",
    "    for r in res:\n",
    "        if len(r) > length:\n",
    "            length = len(r)\n",
    "    return length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучающая выборка:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic['words_count'] = toxic['comment_text'].apply(words_count)\n",
    "toxic['sents_count'] = toxic['comment_text'].apply(sents_count) \n",
    "toxic['chars_count'] = toxic['comment_text'].apply(chars_count)   \n",
    "toxic['mean_word_length'] = toxic['comment_text'].apply(mean_word_length) \n",
    "toxic['mean_sent_length'] = toxic['comment_text'].apply(mean_sent_length) \n",
    "toxic['caps_percentage'] = toxic['comment_text'].apply(caps_percentage)   \n",
    "toxic['punctuation_percentage'] = toxic['comment_text'].apply(punctuation_percentage) \n",
    "toxic['word_repeat_ratio'] = toxic['comment_text'].apply(word_repeat_ratio)  \n",
    "toxic['character_repeat'] = toxic['comment_text'].apply(character_repeat)   \n",
    "toxic['punctuation_repeat'] = toxic['comment_text'].apply(punctuation_repeat)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>words_count</th>\n",
       "      <th>sents_count</th>\n",
       "      <th>chars_count</th>\n",
       "      <th>mean_word_length</th>\n",
       "      <th>mean_sent_length</th>\n",
       "      <th>caps_percentage</th>\n",
       "      <th>punctuation_percentage</th>\n",
       "      <th>word_repeat_ratio</th>\n",
       "      <th>character_repeat</th>\n",
       "      <th>punctuation_repeat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>202401</th>\n",
       "      <td>aac04d8feb3e4b39</td>\n",
       "      <td>\" \\n :Left more detail under the review at Tal...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>86</td>\n",
       "      <td>5.38</td>\n",
       "      <td>19.00</td>\n",
       "      <td>9.30</td>\n",
       "      <td>9.30</td>\n",
       "      <td>7.14</td>\n",
       "      <td>7.69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84162</th>\n",
       "      <td>e12a43cefe51d6fe</td>\n",
       "      <td>\"\\n\\nSpeedy deletion of \"\"Shrini\"\"\\n A page yo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>123</td>\n",
       "      <td>7</td>\n",
       "      <td>730</td>\n",
       "      <td>4.88</td>\n",
       "      <td>20.71</td>\n",
       "      <td>1.23</td>\n",
       "      <td>3.15</td>\n",
       "      <td>26.44</td>\n",
       "      <td>8.13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62253</th>\n",
       "      <td>a6956e341824c2b4</td>\n",
       "      <td>)\\na cowards site, that must stop changing thi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>6</td>\n",
       "      <td>410</td>\n",
       "      <td>4.02</td>\n",
       "      <td>17.17</td>\n",
       "      <td>28.78</td>\n",
       "      <td>5.85</td>\n",
       "      <td>14.29</td>\n",
       "      <td>6.17</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113431</th>\n",
       "      <td>5e98a73ecce25fcd</td>\n",
       "      <td>Arg. \\n\\nTHis shit is not CREDIBLE!</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>35.48</td>\n",
       "      <td>6.45</td>\n",
       "      <td>14.29</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56104</th>\n",
       "      <td>95ebdc00350058cb</td>\n",
       "      <td>dhdhhdfh \\n\\ndeleting an account isnt going to...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>5.11</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0.00</td>\n",
       "      <td>22.22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75437</th>\n",
       "      <td>c9cf6a055dfac6ee</td>\n",
       "      <td>\"\\n Comment redacted. We'll all be reduced to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>3</td>\n",
       "      <td>249</td>\n",
       "      <td>4.08</td>\n",
       "      <td>19.33</td>\n",
       "      <td>4.82</td>\n",
       "      <td>5.22</td>\n",
       "      <td>19.05</td>\n",
       "      <td>12.24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137334</th>\n",
       "      <td>dece133d021adb75</td>\n",
       "      <td>\"\\n\\n The borders of the new state were not sp...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>87</td>\n",
       "      <td>7</td>\n",
       "      <td>472</td>\n",
       "      <td>4.34</td>\n",
       "      <td>15.29</td>\n",
       "      <td>3.81</td>\n",
       "      <td>4.45</td>\n",
       "      <td>43.24</td>\n",
       "      <td>2.30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59050</th>\n",
       "      <td>9e2545dd971e7ed0</td>\n",
       "      <td>}}\\n{{Old AfD multi|page=Wee Shu Min elitism c...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>79</td>\n",
       "      <td>8.44</td>\n",
       "      <td>13.00</td>\n",
       "      <td>8.86</td>\n",
       "      <td>12.66</td>\n",
       "      <td>10.00</td>\n",
       "      <td>22.22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60829</th>\n",
       "      <td>a2d9eab4c472e2cb</td>\n",
       "      <td>Of course, it's an OR review of mine, just to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "      <td>7</td>\n",
       "      <td>601</td>\n",
       "      <td>4.55</td>\n",
       "      <td>18.00</td>\n",
       "      <td>2.50</td>\n",
       "      <td>3.16</td>\n",
       "      <td>24.42</td>\n",
       "      <td>8.26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107437</th>\n",
       "      <td>3e571977469fe055</td>\n",
       "      <td>I don't give a damn about religion, but it's o...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>327</td>\n",
       "      <td>4.55</td>\n",
       "      <td>33.00</td>\n",
       "      <td>2.75</td>\n",
       "      <td>3.06</td>\n",
       "      <td>22.92</td>\n",
       "      <td>1.67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                       comment_text  \\\n",
       "202401  aac04d8feb3e4b39  \" \\n :Left more detail under the review at Tal...   \n",
       "84162   e12a43cefe51d6fe  \"\\n\\nSpeedy deletion of \"\"Shrini\"\"\\n A page yo...   \n",
       "62253   a6956e341824c2b4  )\\na cowards site, that must stop changing thi...   \n",
       "113431  5e98a73ecce25fcd                Arg. \\n\\nTHis shit is not CREDIBLE!   \n",
       "56104   95ebdc00350058cb  dhdhhdfh \\n\\ndeleting an account isnt going to...   \n",
       "75437   c9cf6a055dfac6ee  \"\\n Comment redacted. We'll all be reduced to ...   \n",
       "137334  dece133d021adb75  \"\\n\\n The borders of the new state were not sp...   \n",
       "59050   9e2545dd971e7ed0  }}\\n{{Old AfD multi|page=Wee Shu Min elitism c...   \n",
       "60829   a2d9eab4c472e2cb  Of course, it's an OR review of mine, just to ...   \n",
       "107437  3e571977469fe055  I don't give a damn about religion, but it's o...   \n",
       "\n",
       "        toxic  severe_toxic  obscene  threat  insult  identity_hate  \\\n",
       "202401      0             0        0       0       0              0   \n",
       "84162       0             0        0       0       0              0   \n",
       "62253       1             0        1       0       0              0   \n",
       "113431      1             0        1       0       0              0   \n",
       "56104       0             0        0       0       0              0   \n",
       "75437       0             0        0       0       0              0   \n",
       "137334      0             0        0       0       0              0   \n",
       "59050       0             0        0       0       0              0   \n",
       "60829       0             0        0       0       0              0   \n",
       "107437      1             0        0       0       0              0   \n",
       "\n",
       "        words_count  sents_count  chars_count  mean_word_length  \\\n",
       "202401           13            1           86              5.38   \n",
       "84162           123            7          730              4.88   \n",
       "62253            81            6          410              4.02   \n",
       "113431            6            2           31              4.00   \n",
       "56104             9            1           56              5.11   \n",
       "75437            49            3          249              4.08   \n",
       "137334           87            7          472              4.34   \n",
       "59050             9            1           79              8.44   \n",
       "60829           109            7          601              4.55   \n",
       "107437           60            2          327              4.55   \n",
       "\n",
       "        mean_sent_length  caps_percentage  punctuation_percentage  \\\n",
       "202401             19.00             9.30                    9.30   \n",
       "84162              20.71             1.23                    3.15   \n",
       "62253              17.17            28.78                    5.85   \n",
       "113431              4.00            35.48                    6.45   \n",
       "56104              10.00             0.00                    1.79   \n",
       "75437              19.33             4.82                    5.22   \n",
       "137334             15.29             3.81                    4.45   \n",
       "59050              13.00             8.86                   12.66   \n",
       "60829              18.00             2.50                    3.16   \n",
       "107437             33.00             2.75                    3.06   \n",
       "\n",
       "        word_repeat_ratio  character_repeat  punctuation_repeat  \n",
       "202401               7.14              7.69                   1  \n",
       "84162               26.44              8.13                   1  \n",
       "62253               14.29              6.17                   3  \n",
       "113431              14.29              0.00                   1  \n",
       "56104                0.00             22.22                   1  \n",
       "75437               19.05             12.24                   1  \n",
       "137334              43.24              2.30                   1  \n",
       "59050               10.00             22.22                   0  \n",
       "60829               24.42              8.26                   1  \n",
       "107437              22.92              1.67                   1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тестовая выборка:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic_test['words_count'] = toxic_test['content'].apply(words_count)\n",
    "toxic_test['sents_count'] = toxic_test['content'].apply(sents_count) \n",
    "toxic_test['chars_count'] = toxic_test['content'].apply(chars_count)\n",
    "toxic_test['mean_word_length'] = toxic_test['content'].apply(mean_word_length) \n",
    "toxic_test['mean_sent_length'] = toxic_test['content'].apply(mean_sent_length) \n",
    "toxic_test['caps_percentage'] = toxic_test['content'].apply(caps_percentage)   \n",
    "toxic_test['punctuation_percentage'] = toxic_test['content'].apply(punctuation_percentage) \n",
    "toxic_test['word_repeat_ratio'] = toxic_test['content'].apply(word_repeat_ratio)  \n",
    "toxic_test['character_repeat'] = toxic_test['content'].apply(character_repeat)  \n",
    "toxic_test['punctuation_repeat'] = toxic_test['content'].apply(punctuation_repeat)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>content</th>\n",
       "      <th>lang</th>\n",
       "      <th>words_count</th>\n",
       "      <th>sents_count</th>\n",
       "      <th>chars_count</th>\n",
       "      <th>mean_word_length</th>\n",
       "      <th>mean_sent_length</th>\n",
       "      <th>caps_percentage</th>\n",
       "      <th>punctuation_percentage</th>\n",
       "      <th>word_repeat_ratio</th>\n",
       "      <th>character_repeat</th>\n",
       "      <th>punctuation_repeat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Doctor Who adlı viki başlığına 12. doctor olar...</td>\n",
       "      <td>tr</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>137</td>\n",
       "      <td>6.21</td>\n",
       "      <td>5.50</td>\n",
       "      <td>3.65</td>\n",
       "      <td>2.92</td>\n",
       "      <td>10.53</td>\n",
       "      <td>10.53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Вполне возможно, но я пока не вижу необходимо...</td>\n",
       "      <td>ru</td>\n",
       "      <td>76</td>\n",
       "      <td>6</td>\n",
       "      <td>456</td>\n",
       "      <td>5.01</td>\n",
       "      <td>14.50</td>\n",
       "      <td>3.73</td>\n",
       "      <td>2.63</td>\n",
       "      <td>15.87</td>\n",
       "      <td>3.95</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Quindi tu sei uno di quelli   conservativi  , ...</td>\n",
       "      <td>it</td>\n",
       "      <td>49</td>\n",
       "      <td>7</td>\n",
       "      <td>279</td>\n",
       "      <td>4.49</td>\n",
       "      <td>9.29</td>\n",
       "      <td>3.58</td>\n",
       "      <td>7.89</td>\n",
       "      <td>19.05</td>\n",
       "      <td>20.41</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Malesef gerçekleştirilmedi ancak şöyle bir şey...</td>\n",
       "      <td>tr</td>\n",
       "      <td>81</td>\n",
       "      <td>13</td>\n",
       "      <td>629</td>\n",
       "      <td>6.43</td>\n",
       "      <td>7.62</td>\n",
       "      <td>2.38</td>\n",
       "      <td>3.02</td>\n",
       "      <td>20.90</td>\n",
       "      <td>9.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>:Resim:Seldabagcan.jpg resminde kaynak sorunu ...</td>\n",
       "      <td>tr</td>\n",
       "      <td>175</td>\n",
       "      <td>17</td>\n",
       "      <td>1513</td>\n",
       "      <td>7.35</td>\n",
       "      <td>12.00</td>\n",
       "      <td>1.85</td>\n",
       "      <td>2.18</td>\n",
       "      <td>35.71</td>\n",
       "      <td>9.71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Le truc le plus important dans ta tirade c est...</td>\n",
       "      <td>fr</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>161</td>\n",
       "      <td>3.91</td>\n",
       "      <td>11.33</td>\n",
       "      <td>1.86</td>\n",
       "      <td>1.24</td>\n",
       "      <td>13.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>20px Caro editor, encontramos problemas na edi...</td>\n",
       "      <td>pt</td>\n",
       "      <td>70</td>\n",
       "      <td>6</td>\n",
       "      <td>434</td>\n",
       "      <td>5.06</td>\n",
       "      <td>12.83</td>\n",
       "      <td>3.92</td>\n",
       "      <td>2.07</td>\n",
       "      <td>21.57</td>\n",
       "      <td>2.86</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>el skate es unos de los deportes favoritos de ...</td>\n",
       "      <td>es</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>142</td>\n",
       "      <td>4.30</td>\n",
       "      <td>27.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>3.70</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Me doy la bienvenida. A este usuari le gusta c...</td>\n",
       "      <td>es</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>145</td>\n",
       "      <td>4.07</td>\n",
       "      <td>9.00</td>\n",
       "      <td>4.14</td>\n",
       "      <td>5.52</td>\n",
       "      <td>3.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>ES NOTABLEMENTE TENDENCIOSO, NO SE HABLA DE CU...</td>\n",
       "      <td>es</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>267</td>\n",
       "      <td>4.58</td>\n",
       "      <td>53.00</td>\n",
       "      <td>82.02</td>\n",
       "      <td>1.87</td>\n",
       "      <td>23.68</td>\n",
       "      <td>2.08</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            content lang  words_count  \\\n",
       "0   0  Doctor Who adlı viki başlığına 12. doctor olar...   tr           19   \n",
       "1   1   Вполне возможно, но я пока не вижу необходимо...   ru           76   \n",
       "2   2  Quindi tu sei uno di quelli   conservativi  , ...   it           49   \n",
       "3   3  Malesef gerçekleştirilmedi ancak şöyle bir şey...   tr           81   \n",
       "4   4  :Resim:Seldabagcan.jpg resminde kaynak sorunu ...   tr          175   \n",
       "5   5  Le truc le plus important dans ta tirade c est...   fr           32   \n",
       "6   6  20px Caro editor, encontramos problemas na edi...   pt           70   \n",
       "7   7  el skate es unos de los deportes favoritos de ...   es           27   \n",
       "8   8  Me doy la bienvenida. A este usuari le gusta c...   es           29   \n",
       "9   9  ES NOTABLEMENTE TENDENCIOSO, NO SE HABLA DE CU...   es           48   \n",
       "\n",
       "   sents_count  chars_count  mean_word_length  mean_sent_length  \\\n",
       "0            4          137              6.21              5.50   \n",
       "1            6          456              5.01             14.50   \n",
       "2            7          279              4.49              9.29   \n",
       "3           13          629              6.43              7.62   \n",
       "4           17         1513              7.35             12.00   \n",
       "5            3          161              3.91             11.33   \n",
       "6            6          434              5.06             12.83   \n",
       "7            1          142              4.30             27.00   \n",
       "8            4          145              4.07              9.00   \n",
       "9            1          267              4.58             53.00   \n",
       "\n",
       "   caps_percentage  punctuation_percentage  word_repeat_ratio  \\\n",
       "0             3.65                    2.92              10.53   \n",
       "1             3.73                    2.63              15.87   \n",
       "2             3.58                    7.89              19.05   \n",
       "3             2.38                    3.02              20.90   \n",
       "4             1.85                    2.18              35.71   \n",
       "5             1.86                    1.24              13.33   \n",
       "6             3.92                    2.07              21.57   \n",
       "7             0.00                    0.00              20.00   \n",
       "8             4.14                    5.52               3.33   \n",
       "9            82.02                    1.87              23.68   \n",
       "\n",
       "   character_repeat  punctuation_repeat  \n",
       "0             10.53                   1  \n",
       "1              3.95                   1  \n",
       "2             20.41                   3  \n",
       "3              9.88                   1  \n",
       "4              9.71                   1  \n",
       "5              0.00                   1  \n",
       "6              2.86                   1  \n",
       "7              3.70                   0  \n",
       "8              0.00                   1  \n",
       "9              2.08                   1  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic_test.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравним средние статистик по двум выборкам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = pd.DataFrame({'dataset':['train', 'test'],\n",
    "                          'words_count':[toxic['words_count'].mean(), toxic_test['words_count'].mean()],\n",
    "                          'sents_count':[toxic['sents_count'].mean(), toxic_test['sents_count'].mean()],\n",
    "                          'chars_count':[toxic['chars_count'].mean(), toxic_test['chars_count'].mean()],\n",
    "                          'mean_word_length':[toxic['mean_word_length'].mean(), toxic_test['mean_word_length'].mean()],\n",
    "                          'mean_sent_length':[toxic['mean_sent_length'].mean(), toxic_test['mean_sent_length'].mean()],\n",
    "                          'caps_percentage':[toxic['caps_percentage'].mean(), toxic_test['caps_percentage'].mean()],\n",
    "                          'punctuation_percentage':[toxic['punctuation_percentage'].mean(), toxic_test['punctuation_percentage'].mean()],\n",
    "                          'word_repeat_ratio':[toxic['word_repeat_ratio'].mean(), toxic_test['word_repeat_ratio'].mean()],\n",
    "                          'character_repeat':[toxic['character_repeat'].mean(), toxic_test['character_repeat'].mean()],\n",
    "                          'punctuation_repeat':[toxic['punctuation_repeat'].mean(), toxic_test['punctuation_repeat'].mean()]\n",
    "                          })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>words_count</th>\n",
       "      <th>sents_count</th>\n",
       "      <th>chars_count</th>\n",
       "      <th>mean_word_length</th>\n",
       "      <th>mean_sent_length</th>\n",
       "      <th>caps_percentage</th>\n",
       "      <th>punctuation_percentage</th>\n",
       "      <th>word_repeat_ratio</th>\n",
       "      <th>character_repeat</th>\n",
       "      <th>punctuation_repeat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>66.570148</td>\n",
       "      <td>4.301648</td>\n",
       "      <td>372.244524</td>\n",
       "      <td>4.656768</td>\n",
       "      <td>18.462214</td>\n",
       "      <td>5.585575</td>\n",
       "      <td>6.070397</td>\n",
       "      <td>17.015188</td>\n",
       "      <td>9.833525</td>\n",
       "      <td>1.476568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test</td>\n",
       "      <td>58.186172</td>\n",
       "      <td>4.472638</td>\n",
       "      <td>365.822557</td>\n",
       "      <td>5.271352</td>\n",
       "      <td>18.248322</td>\n",
       "      <td>4.521486</td>\n",
       "      <td>3.722610</td>\n",
       "      <td>13.515397</td>\n",
       "      <td>7.366358</td>\n",
       "      <td>1.635586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset  words_count  sents_count  chars_count  mean_word_length  \\\n",
       "0   train    66.570148     4.301648   372.244524          4.656768   \n",
       "1    test    58.186172     4.472638   365.822557          5.271352   \n",
       "\n",
       "   mean_sent_length  caps_percentage  punctuation_percentage  \\\n",
       "0         18.462214         5.585575                6.070397   \n",
       "1         18.248322         4.521486                3.722610   \n",
       "\n",
       "   word_repeat_ratio  character_repeat  punctuation_repeat  \n",
       "0          17.015188          9.833525            1.476568  \n",
       "1          13.515397          7.366358            1.635586  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заметно, что на тестовой выборке несколько меньше среднее количество слов и символов в комментарии, процент капса, пунктуации, повторяющихся слов и символов. Незначительно больше у неё значение только в средней длине комментария в предложениях."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь посмотрим на языки, представленные в тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tr    14000\n",
       "pt    11012\n",
       "ru    10948\n",
       "fr    10920\n",
       "it     8494\n",
       "es     8438\n",
       "Name: lang, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic_test['lang'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Больше всего комментариев на турецком, меньше всего — на испанском. \n",
    "Посмотрим, различаются ли как-то метрики между языками."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>words_count</th>\n",
       "      <th>sents_count</th>\n",
       "      <th>chars_count</th>\n",
       "      <th>mean_word_length</th>\n",
       "      <th>mean_sent_length</th>\n",
       "      <th>caps_percentage</th>\n",
       "      <th>punctuation_percentage</th>\n",
       "      <th>word_repeat_ratio</th>\n",
       "      <th>character_repeat</th>\n",
       "      <th>punctuation_repeat</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lang</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>es</th>\n",
       "      <td>32405.344039</td>\n",
       "      <td>52.685945</td>\n",
       "      <td>3.179900</td>\n",
       "      <td>298.016947</td>\n",
       "      <td>4.663715</td>\n",
       "      <td>23.455702</td>\n",
       "      <td>6.975967</td>\n",
       "      <td>3.348764</td>\n",
       "      <td>15.611833</td>\n",
       "      <td>3.687330</td>\n",
       "      <td>1.655487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr</th>\n",
       "      <td>31676.724176</td>\n",
       "      <td>67.026282</td>\n",
       "      <td>4.105495</td>\n",
       "      <td>376.191758</td>\n",
       "      <td>4.567502</td>\n",
       "      <td>21.315888</td>\n",
       "      <td>3.796771</td>\n",
       "      <td>3.591158</td>\n",
       "      <td>16.221549</td>\n",
       "      <td>8.545807</td>\n",
       "      <td>1.645513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it</th>\n",
       "      <td>31916.568048</td>\n",
       "      <td>57.359430</td>\n",
       "      <td>3.755121</td>\n",
       "      <td>340.656463</td>\n",
       "      <td>4.876001</td>\n",
       "      <td>20.535257</td>\n",
       "      <td>3.873120</td>\n",
       "      <td>3.973826</td>\n",
       "      <td>13.380492</td>\n",
       "      <td>15.597780</td>\n",
       "      <td>1.956911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pt</th>\n",
       "      <td>31795.557937</td>\n",
       "      <td>63.962768</td>\n",
       "      <td>4.818289</td>\n",
       "      <td>381.856974</td>\n",
       "      <td>4.910379</td>\n",
       "      <td>17.569461</td>\n",
       "      <td>4.819306</td>\n",
       "      <td>4.205549</td>\n",
       "      <td>15.268585</td>\n",
       "      <td>5.302015</td>\n",
       "      <td>1.750363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ru</th>\n",
       "      <td>31952.666423</td>\n",
       "      <td>53.267811</td>\n",
       "      <td>4.678754</td>\n",
       "      <td>349.104859</td>\n",
       "      <td>5.503438</td>\n",
       "      <td>15.687345</td>\n",
       "      <td>3.929187</td>\n",
       "      <td>4.281545</td>\n",
       "      <td>11.442157</td>\n",
       "      <td>6.042558</td>\n",
       "      <td>1.454238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tr</th>\n",
       "      <td>31825.560000</td>\n",
       "      <td>54.410000</td>\n",
       "      <td>5.540429</td>\n",
       "      <td>414.331643</td>\n",
       "      <td>6.528890</td>\n",
       "      <td>13.866200</td>\n",
       "      <td>4.229705</td>\n",
       "      <td>3.081095</td>\n",
       "      <td>10.465159</td>\n",
       "      <td>6.328634</td>\n",
       "      <td>1.472429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id words_count sents_count chars_count mean_word_length  \\\n",
       "              mean        mean        mean        mean             mean   \n",
       "lang                                                                      \n",
       "es    32405.344039   52.685945    3.179900  298.016947         4.663715   \n",
       "fr    31676.724176   67.026282    4.105495  376.191758         4.567502   \n",
       "it    31916.568048   57.359430    3.755121  340.656463         4.876001   \n",
       "pt    31795.557937   63.962768    4.818289  381.856974         4.910379   \n",
       "ru    31952.666423   53.267811    4.678754  349.104859         5.503438   \n",
       "tr    31825.560000   54.410000    5.540429  414.331643         6.528890   \n",
       "\n",
       "     mean_sent_length caps_percentage punctuation_percentage  \\\n",
       "                 mean            mean                   mean   \n",
       "lang                                                           \n",
       "es          23.455702        6.975967               3.348764   \n",
       "fr          21.315888        3.796771               3.591158   \n",
       "it          20.535257        3.873120               3.973826   \n",
       "pt          17.569461        4.819306               4.205549   \n",
       "ru          15.687345        3.929187               4.281545   \n",
       "tr          13.866200        4.229705               3.081095   \n",
       "\n",
       "     word_repeat_ratio character_repeat punctuation_repeat  \n",
       "                  mean             mean               mean  \n",
       "lang                                                        \n",
       "es           15.611833         3.687330           1.655487  \n",
       "fr           16.221549         8.545807           1.645513  \n",
       "it           13.380492        15.597780           1.956911  \n",
       "pt           15.268585         5.302015           1.750363  \n",
       "ru           11.442157         6.042558           1.454238  \n",
       "tr           10.465159         6.328634           1.472429  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic_test.groupby('lang').agg(['mean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из любопытных наблюдений можно отметить, что самые длинные комментарии оставляли на турецком, но при этом средняя длина предложения у них самая низкая, а у испанского языка ситуация диаметрально противоположная. Кроме того, в итальянском значительно чаще, чем где-либо еще, встречались повторения символов, а также капс."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic.to_csv(r'toxic_sample.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline модель"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для этой части выбрала пункт за 1.5 балла (бейзлайн модель из sklearn (векторайзер + модель) c подбором параметров в grid_search (как минимум 10 параметров))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = toxic.comment_text.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = toxic.toxic.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(max_features=10000, min_df=0.01, max_df=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cv = count_vect.fit_transform(X_train)\n",
    "X_test_cv = count_vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bestparams(model, grid, folds, data, classes):\n",
    "    grid_search = GridSearchCV(model, param_grid=grid, cv=folds, scoring='f1_macro')\n",
    "    grid_search.fit(data, classes) \n",
    "    return grid_search.best_score_, grid_search.best_params_, grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [LogisticRegression(), LinearSVC(), SGDClassifier()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "grids = [{'class_weight' : ['balanced', None], 'C': [0.0001, 0.001, 0.001, 0.01, 1, 10,\n",
    "                                                    100, 1000], 'max_iter': [500, 700]},\n",
    "        {'loss' : ['hinge', 'squared_hinge'], 'C': [0.0001, 0.001, 0.001, 0.01, 1, 10,\n",
    "                                                    100, 1000], 'intercept_scaling' : [1, 2]},\n",
    "        {'alpha': [0.0001, 0.05, 0.1], 'max_iter': [200, 300]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fold = 6\n",
    "folds = KFold(n_splits=n_fold, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosenmodels = []\n",
    "trainscores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score is 0.7214350733537795\n",
      "Best parameters are {'C': 100, 'class_weight': None, 'max_iter': 500}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbookpro/miniconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score is 0.7219616766814392\n",
      "Best parameters are {'C': 10, 'intercept_scaling': 2, 'loss': 'squared_hinge'}\n",
      "Best score is 0.7132063761331536\n",
      "Best parameters are {'alpha': 0.0001, 'max_iter': 200}\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    best_score, best_params, best_estimator = bestparams(models[i], grids[i], folds, X_train_cv, y_train)\n",
    "    print('Best score is {}'.format(best_score))\n",
    "    print('Best parameters are {}'.format(best_params))\n",
    "    trainscores.append(best_score)\n",
    "    chosenmodels.append(best_estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самый лучший результат показала модель с LinearSVC и параметрами C=10, intercept_scaling=2, loss=squared_hinge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ансамбли"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь выбрала часть за 2 балла (ансамбль из моделей в sklearn)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = MultinomialNB()\n",
    "clf2 = LogisticRegression(C=100, class_weight=None, max_iter=500)\n",
    "clf3 = GaussianNB()\n",
    "clf4 = SGDClassifier(loss='log', alpha=0.0001, max_iter=200)\n",
    "clf5 = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "eclf = VotingClassifier(estimators=[('clf1', clf1), ('clf2', clf2), ('clf3', clf3), ('clf4', clf4),\n",
    "                                    ('clf5', clf5)], voting='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.4 s, sys: 205 ms, total: 17.6 s\n",
      "Wall time: 16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "voting = Pipeline([\n",
    "    ('vect', CountVectorizer(analyzer='word', max_features=500)),\n",
    "    ('tfidf', TfidfTransformer(sublinear_tf=True)),\n",
    "    ('to_dense', FunctionTransformer(lambda x: x.todense(), accept_sparse=True)), \n",
    "    ('clf', eclf),\n",
    "    ])\n",
    "voting = voting.fit(X_train[:20000], y_train[:20000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = voting.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:   0.82\n",
      "Recall:   0.72\n",
      "F1-measure:   0.76\n",
      "Accuracy:   0.93\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision: {0:6.2f}\".format(precision_score(y_test, predict, average='macro')))\n",
    "print(\"Recall: {0:6.2f}\".format(recall_score(y_test, predict, average='macro')))\n",
    "print(\"F1-measure: {0:6.2f}\".format(f1_score(y_test, predict, average='macro')))\n",
    "print(\"Accuracy: {0:6.2f}\".format(accuracy_score(y_test, predict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Любая нейронная модель (минимум 5 слоев) с Dropout, Pooling и колбеками - 2 балла."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    tokens = text.lower().split()\n",
    "    tokens = [token.strip(punctuation) for token in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = Counter()\n",
    "for text in toxic['comment_text']:\n",
    "    vocab.update(preprocess(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_vocab = set()\n",
    "for word in vocab:\n",
    "    if vocab[word] > 2:\n",
    "        filtered_vocab.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2id = {'UNK':1, 'PAD':0}\n",
    "\n",
    "for word in filtered_vocab:\n",
    "    word2id[word] = len(word2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = {i:word for word, i in word2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "\n",
    "for text in toxic['comment_text']:\n",
    "    tokens = preprocess(text)\n",
    "    ids = [word2id.get(token, 1) for token in tokens]\n",
    "    X.append(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = max(len(x) for x in X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "MEAN_LEN = np.median([len(x) for x in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.keras.preprocessing.sequence.pad_sequences(X, maxlen=MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67065, 1990)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = toxic.toxic.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.05, random_state=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/macbookpro/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /Users/macbookpro/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /Users/macbookpro/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.layers.Input(shape=(MAX_LEN,))\n",
    "embeddings = tf.keras.layers.Embedding(input_dim=len(word2id), output_dim=40)(inputs)\n",
    "\n",
    "conv_1 = tf.keras.layers.Conv1D(kernel_size=5, filters=10, strides=2)(embeddings)\n",
    "conv_2 = tf.keras.layers.Conv1D(kernel_size=5, filters=20, strides=2)(conv_1)\n",
    "pool_1 = tf.keras.layers.AveragePooling1D()(conv_2)\n",
    "drop_1 = tf.keras.layers.Dropout(0.1)(pool_1)\n",
    "conv_3 = tf.keras.layers.Conv1D(kernel_size=5, filters=30, strides=2)(drop_1)\n",
    "pool_2 = tf.keras.layers.AveragePooling1D()(conv_3)\n",
    "drop_2 = tf.keras.layers.Dropout(0.1)(pool_2)\n",
    "\n",
    "concat = tf.keras.layers.Flatten()(drop_1)\n",
    "dense = tf.keras.layers.Dense(64, activation='relu')(concat)\n",
    "outputs = tf.keras.layers.Dense(1, activation='sigmoid')(dense)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=[f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = tf.keras.callbacks.ModelCheckpoint('model.weights', \n",
    "                                                monitor='val_f1', \n",
    "                                                verbose=1, \n",
    "                                                save_weights_only=True, \n",
    "                                                save_best_only=True,\n",
    "                                                mode='max', \n",
    "                                                save_freq='epoch' \n",
    "                                               )\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_f1', \n",
    "                                              min_delta=0.01, \n",
    "                                              patience=3, \n",
    "                                              verbose=1, \n",
    "                                              mode='max',\n",
    "                                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 63711 samples, validate on 3354 samples\n",
      "Epoch 1/10\n",
      "63000/63711 [============================>.] - ETA: 0s - loss: 0.3669 - f1: 0.0000e+00\n",
      "Epoch 00001: val_f1 improved from -inf to 0.00000, saving model to model.weights\n",
      "63711/63711 [==============================] - 54s 846us/sample - loss: 0.3669 - f1: 0.0000e+00 - val_loss: 0.3154 - val_f1: 0.0000e+00\n",
      "Epoch 2/10\n",
      "63000/63711 [============================>.] - ETA: 0s - loss: 0.3188 - f1: 0.0022\n",
      "Epoch 00002: val_f1 did not improve from 0.00000\n",
      "63711/63711 [==============================] - 47s 742us/sample - loss: 0.3183 - f1: 0.0021 - val_loss: 0.3095 - val_f1: 0.0000e+00\n",
      "Epoch 3/10\n",
      "63000/63711 [============================>.] - ETA: 0s - loss: 0.3002 - f1: 0.0093\n",
      "Epoch 00003: val_f1 improved from 0.00000 to 0.02703, saving model to model.weights\n",
      "63711/63711 [==============================] - 53s 836us/sample - loss: 0.3001 - f1: 0.0089 - val_loss: 0.2859 - val_f1: 0.0270\n",
      "Epoch 4/10\n",
      "63000/63711 [============================>.] - ETA: 0s - loss: 0.2621 - f1: 0.0514\n",
      "Epoch 00004: val_f1 improved from 0.02703 to 0.16525, saving model to model.weights\n",
      "63711/63711 [==============================] - 45s 699us/sample - loss: 0.2622 - f1: 0.0542 - val_loss: 0.2444 - val_f1: 0.1653\n",
      "Epoch 5/10\n",
      "63000/63711 [============================>.] - ETA: 0s - loss: 0.2166 - f1: 0.3435\n",
      "Epoch 00005: val_f1 improved from 0.16525 to 0.34358, saving model to model.weights\n",
      "63711/63711 [==============================] - 49s 771us/sample - loss: 0.2165 - f1: 0.3486 - val_loss: 0.2302 - val_f1: 0.3436\n",
      "Epoch 6/10\n",
      "63000/63711 [============================>.] - ETA: 0s - loss: 0.1816 - f1: 0.5064\n",
      "Epoch 00006: val_f1 improved from 0.34358 to 0.43039, saving model to model.weights\n",
      "63711/63711 [==============================] - 45s 711us/sample - loss: 0.1816 - f1: 0.5073 - val_loss: 0.2184 - val_f1: 0.4304\n",
      "Epoch 7/10\n",
      "63000/63711 [============================>.] - ETA: 0s - loss: 0.1512 - f1: 0.6211\n",
      "Epoch 00007: val_f1 improved from 0.43039 to 0.45147, saving model to model.weights\n",
      "63711/63711 [==============================] - 45s 709us/sample - loss: 0.1512 - f1: 0.6211 - val_loss: 0.2202 - val_f1: 0.4515\n",
      "Epoch 8/10\n",
      "63000/63711 [============================>.] - ETA: 0s - loss: 0.1256 - f1: 0.7071\n",
      "Epoch 00008: val_f1 improved from 0.45147 to 0.49812, saving model to model.weights\n",
      "63711/63711 [==============================] - 49s 764us/sample - loss: 0.1255 - f1: 0.7065 - val_loss: 0.2381 - val_f1: 0.4981\n",
      "Epoch 9/10\n",
      "63000/63711 [============================>.] - ETA: 0s - loss: 0.1061 - f1: 0.7654\n",
      "Epoch 00009: val_f1 did not improve from 0.49812\n",
      "63711/63711 [==============================] - 49s 771us/sample - loss: 0.1058 - f1: 0.7683 - val_loss: 0.2622 - val_f1: 0.3971\n",
      "Epoch 10/10\n",
      "63000/63711 [============================>.] - ETA: 0s - loss: 0.0913 - f1: 0.8046\n",
      "Epoch 00010: val_f1 did not improve from 0.49812\n",
      "63711/63711 [==============================] - 45s 702us/sample - loss: 0.0913 - f1: 0.8055 - val_loss: 0.2918 - val_f1: 0.4870\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa9627fd190>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, \n",
    "          validation_data=(X_valid, y_valid),\n",
    "          batch_size=3000,\n",
    "          epochs=10,\n",
    "          callbacks=[checkpoint, early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 1990)]            0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 1990, 40)          1658920   \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 993, 10)           2010      \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 495, 20)           1020      \n",
      "_________________________________________________________________\n",
      "average_pooling1d (AveragePo (None, 247, 20)           0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 247, 20)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4940)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                316224    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 1,978,239\n",
      "Trainable params: 1,978,239\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Поиск аутлаеров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = toxic.sample(frac=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6706, 8)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(max_features=10000, min_df=5, ngram_range=(1,2), max_df=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(min_df=0.02, max_df=0.5, max_features=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tfidf.fit_transform(sample['comment_text'])\n",
    "y = sample['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "sample = X\n",
    "X_pca = pca.fit_transform(sample.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DBSCAN(algorithm='auto', eps=0.02, leaf_size=30, metric='euclidean',\n",
       "       metric_params=None, min_samples=10, n_jobs=None, p=None)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster = DBSCAN(min_samples = 10, eps = 0.02)\n",
    "cluster.fit(X_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{-1, 0, 1, 2, 3, 4, 5}"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(cluster.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Coefficient: -0.255\n",
      "Homogeneity: 0.183\n",
      "Completeness: 0.018\n",
      "V-measure: 0.033\n",
      "Adjusted Rand Index: 0.002\n",
      "Adjusted Mutual Information: -0.001\n"
     ]
    }
   ],
   "source": [
    "print(\"Silhouette Coefficient: %0.3f\" % metrics.silhouette_score(X[:8000], labels[:8000]))\n",
    "print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(y, labels)) \n",
    "print(\"Completeness: %0.3f\" % metrics.completeness_score(y, labels)) \n",
    "print(\"V-measure: %0.3f\" % metrics.v_measure_score(y, labels))\n",
    "print(\"Adjusted Rand Index: %0.3f\" % metrics.adjusted_rand_score(y, labels))\n",
    "print(\"Adjusted Mutual Information: %0.3f\" % metrics.adjusted_mutual_info_score(y, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [i for i, label in enumerate(cluster.labels_) if label == -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найти что-то необычное не удалось, но приведенные ниже примеры отличаются либо лаконичностью, либо избыточной длиной, либо использованием необычных ругательств."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "comment_text    Hi Fracophonie,\\n\\nThanks for taking the time to write such a long message - I appreciate this.\\n\\nIn terms of what I said about the age - I didn't mean to cause offense. I thought I read somewhere that you had to be over 18 to make these decisions but I think I was getting confused with the check user privileges. \\n\\nI have already read some of those policies but will read the rest later today. I am not a troll - I just need time to get used to all these acronyms, policies etc.\\n\\nFrom what started out with me writing an article about my favourite website has turned into a massive thing which was not what I was expecting.\\n\\nI really don't have any more time to argue and debate with the usrs since its clear they just want it deleted despite what I have said. For example one user just wrote there is another site called Amirite.net. This is Amirite.com!! This is precisely why I had to keep responding on the AFC delete page. \\n\\nIn terms of the rest I agree to do them (of course I can only apologise once I am unblocked) - can you apologise for me?\\n\\nOn a side note I am actually French and Jewish (shame about the gay part though:)\n",
       "toxic           0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
       "Name: 542, dtype: object"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic.loc[542, ['comment_text', 'toxic']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "comment_text    \"\\n\\n Past Masters vs. Rarities \\n\\nI'm creating a chart for my own use that includes U.S. albums, since there are so many differences in the early albums. As a U.S. fan, I'm faced with the issue of whether to have U.S. albums, U.K. albums or both on my iPod? I will post my chart on my talk page so that others can judge whether it's worthy of including here. I realize there will be problems, including the lack of Canadian albums. My purpose is simply to record the first ALBUM appearance in both the U.K. and U.S. of each song.\\n\\nI notice that a number of U.K. songs are listed as Past Masters when they actually first appeared on Rarities (1978 The Beatles album). I don't know the reason for this if the purpose is to list the first appearance on an album. Can someone explain? Or should they be changed to Rarities?  \"\n",
       "Name: 688, dtype: object"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic.loc[688, ['comment_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "comment_text    Our Talk Archives: 1 2 3 4 5 6 7\n",
       "Name: 947, dtype: object"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic.loc[947, ['comment_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "comment_text    \"\\nI understand your position and think that your point is perfectly valid. However, I don't deem \"\"Iaşi-Chişinău\"\" a creation of Wikipedia, even with the lack of historical sources for that effect in the English language. I'll think more about this tomorrow. Thank you for explaining your position to me with such accurate detail. Best regards, nd \"\n",
       "Name: 951, dtype: object"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic.loc[951, ['comment_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "comment_text    \"I'm back. I already created  ID (occasionally forget to log in but you can see the same class C when I do) I collected a massive number of diff edits on Balkanfever who pretends to be neutral but is  on record] getting blocked for saying this about Greeks under a previous handle. (not to mention his personal talk page is one big anti-Greek rant fest pointing to questionable FYROM news sources with highly exaggerated sensationalist titles)\\n\\n\"\"No, Assfuckers (has a nice ring to it D) use it as a pejorative term. \\n\\nI was ready to pull the trigger on both him, admin Futper, and a few others (e.g. Macedoniaboy who says he is a \"\"proud fighter for united Macedonia on his talk page) with a detailed complaint about anti-Greek propaganda but since Futper managed a civil discussion with me and now seems to be sticking to debating articles (rather than threats of blocking)  I'm going to avoid escalating this further for now. ns. \\n\\nAs for the current naming disputing article... I agree with you that some FYROM citizens honestly believe their claims but I don't think that reduces the existential threat to Greece. Communism fell 17 years ago in Yugoslavia and the FYROM government appears to be getting worse not better (imagine if in two hundred years they call themselves \"\"ethnic Athenians\"\" and the cycle continues until their is no Greece left). \\n\\nThere appear to be important quotes missing from the naming dispute article that clearly demonstrate that FYROM leadership are confused about their own national identity (and confusing their own citizens in the process unfortunately). I tried to add this to the talk page of the article but Futper deleted it (arguing ancient Macedon is unrelated to the article even though his own editing history shows him adding an edit arguing that ancient Macedon wasn't Greek) I didn't want to get into a revert war over simply a discussion of perceived facts but since I didn't think those facts should be censored either I thought perhaps you could add them to discussion on the naming dispute talk page. (assuming you see it as relevant yourself of course)\\n\\nFebruary 26, 1992: The FYROM's President Kirov Gligorov, at an interview by the Foreign Information Service daily report, Easten Europe, stated: '\"\"We are Slavs, who came to the region in the sixth century. We are not descendants of the ancient Macedonians.'\\n\\n\"\"January 22, 1999: The FYROM's Ambassador in Washington D.C., Mrs. Ljubica Acevska, gave a speech on the present situation in the Balkans, she stated: '\"\"We do not claim to be descendants of Alexander the Great. We are Slavs and we speak a Slavic language. Greece is The FYROM's second largest trading partner and its number one \"\"investor.\"\"'\\n\\nFebruary 24, 1999: The FYROM.'s Ambassador to Canada, Gyordan Veselinov, in an interview with the \"\"Ottawa Citizen\"\", he admitted: '\"\"We are not related to the northern Greeks who produced leaders like Philip and Alexander the Great. We are Slavs and our language is closely related to Bulgarian. There is some confusion about our identity.\"\"'\\n\\nI think the above needs to be compared to that of their current hard line prime minister's recent behavior. He directly contradicts FYROM's own government's previous comments about themselves (that apparently was unauthentically meant to assure foreigners that Greeks were imagining FYROM propaganda and to reduce the issue to a childish dispute over simply names.. in order to get recognition)\\n\\nPrime Minister Gruevski officially meets Prince Ghazanfar of Pakistan] who claims to be related to Alexander the Great.. then uses it as an opportunity to suggest FYROM citizens are related to ancient Macedonians. (and don't get me started on that incident where Gruevski layed a wreath where a picture of \"\"United Macedonia\"\" was clearly present... which also seems to be missing from the existing article)\\n\\n\"\n",
       "Name: 1379, dtype: object"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic.loc[1379, ['comment_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "comment_text    Can you, or anyone, please tell me what's going on? Email me or something, whatever it takes. This is ridiculous. I don't care for games. ++: t/c\n",
       "Name: 1383, dtype: object"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic.loc[1383, ['comment_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "comment_text    It was not been written as a commercial work, so is not copyrighted, and in the Public domain.\n",
       "Name: 1529, dtype: object"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic.loc[1529, ['comment_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "comment_text    \"\\n\\n Summary of the AfD Debate \\n\\nNegative Votes\\n\\n delete - The original editor was User:Ivygohnair so it was marked as a vanity article for violating WP:AUTO.  Mapetite526 \\n Strong Delete - Ignorance of the rules is not a valid argument for keeping an article. Vyse \\n\\nNeutral Positive Votes\\n\\n Procedural nomination. Speedy A7 was applied, but was contested and this warrants a further look. I'm neutral for now (even though this article doesn't seem to be). ColourBurst \\n\\n Comment/Question:CSD A7 is \"\"Unremarkable people, groups, companies and websites.\"\". Is that the reason for the AfD too? According to Wikipedia:Vanity_guidelines \"\"As explained below, an author's conflict of interest by itself is not a basis for deletion, but lack of assertion of notability is.\"\" Edward Wakelin \\n \\n It is true that I have come into the fray to defend Ivy Goh Nair from speedy deletion and that her last page was actually uploaded by me. I think if you want to apply the \"\"vanity\"\" label because one person edits the other and vice versa, it would only be fair to examine each case on its own merit. Both user:ivygohnair and user:chandrannair are established figures in the field that is being discussed: ie Singapore literature and writing; secondly, it should be considered in their favour that they have used their own names and not fictitious names as user names; If this had been the case, the problem wouldn't have arisen. Therefore I think there is much merit in User: Edward Wakelin remarks above and that an author's conflict of interest is by itself not a basis for deletion. out by Wikipedia. Chandrannair (talk • contribs) .\\n\\n Comment: Let's be nice to newcomers, as per Wikipedia:Please do not bite the newcomers. This seems like a case where newcomers not knowing the \"\"rules\"\" here. An author of 1 bestseller may be notable enough to get an article in an encyclopedia. Perhaps this biography needs some fixing, as per Wikipedia:Biographies of living persons. Deleting is probably unnecessary. PFHLai \\n\\n I have read her book, though I'm not from Singapore and it's better than a lot of the stuff that makes it to the NY Times best seller list. —The preceding unsigned comment was added by 128.91.147.159 (talk • contribs).\\n\\n –New to all this in wikipedia... I think the mood to delete is harsh. This is a user who seems to have made a definite impact in a small place, and is trying to popularise the creative energies of Singapore. Let us be more forgiving! Besides it looks there is actual published reviews as testament to the work. Mcporpington mcporpington Sorry I meant to add to my comment above that the article should NOT be deleted! Mcporpington mcporpington\\n\\n Hi - I am saddened to read such biting, petty comments and suggestions about deleting this article. This person has clearly contributed to Singapore literature and has also been cited by others. signed - Phillygal27\\n\\n I did my military service in Singapore and I love the country. I vote to KEEP. I do not see any conflict of interest hereJean-Louis77 \\n\\nRetrieved from \"\"http://en.wikipedia.org/wiki/Wikipedia:Articles_for_deletion/Ivy_Goh_Nair\"\"\"\n",
       "Name: 1636, dtype: object"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic.loc[1636, ['comment_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "comment_text    Fartsalot56 says f**k you motherclucker!!\n",
       "Name: 1976, dtype: object"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic.loc[1976, ['comment_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "comment_text    \"\\n\\nYou have been blocked for 24 hours.  (Talk)  (Contribs) \"\n",
       "Name: 2229, dtype: object"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic.loc[2229, ['comment_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "comment_text    Attention Wikipedia Administrators \\n\\nUnder mentioned data is for your observations.\\n\\nThis talk page have been misused by the so called intelligent editors, which can be seen by the Archive of this page. \\nArchive-1, have 18 printed pages of A4 size.\\nArchive-2, have 21 printed pages of A4 size.\\nArchive-3, have 28 printed pages of A4 size.\\nArchive-4, have 40 printed pages of A4 size.\\nArchive-5, have 44 printed pages of A4 size.\\nArchive-6, have 57 printed pages of A4 size.\\nArchive-7, have 31 printed pages of A4 size.\\nArchive-8, have 35 printed pages of A4 size.\\nArchive-9, have 29 printed pages of A4 size.\\nArchive-10, have 32 printed pages of A4 size.\\nArchive-11, have 40 printed pages of A4 size.\\nArchive-12, have 15 printed pages of A4 size.\\nArchive-13, have 47 printed pages of A4 size.\\n\\nThe current talk pages have 25 printed pages material of A4 size paper. Total 464 [ Four Hundred Sixty Four] pages approximately have been used in the discussion. What is it? Is Homoeopathy is so controversial subject that such a big discussion cannot solve by anyone? Is it not a shameful condition for all, those who have participated in the discussion? Approximately 500 pages have been used for discussion without any conclusion. The learned editors perhaps avoided to consult the other encyclopedias on the subject matters. Only One percent editors are seen to be serious about the subject matters. Rest of the editors either chatting on this page or spreading unnecessary controversy, which have no mean to the subject. The chatting can be seen with the timings of the editors. If anybody goes and sees the UTC timings of the editors, it looks like they are chatting on this page without any serious intentions. \\n\\nWhat is it and why it is being allowed in this page? User:debbe, 18 April 2007,01:35 PM IST\n",
       "Name: 2447, dtype: object"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic.loc[2447, ['comment_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "comment_text    [name of possible attack site]\n",
       "Name: 2748, dtype: object"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic.loc[2748, ['comment_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "comment_text    You do not know that we have two different categories, 7th octave and whistle register? YOU CREATED THEM. See Minnie Ripperton for an artist with links to both cats.\n",
       "Name: 2980, dtype: object"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic.loc[2980, ['comment_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "comment_text    Wow... \\n\\nSomeone sure is aggressive...XP\n",
       "Name: 3257, dtype: object"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic.loc[3257, ['comment_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "comment_text    NB:  has received a 24h block for WP:3RR violation.\n",
       "Name: 3616, dtype: object"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic.loc[3616, ['comment_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "comment_text    POV\\nWhy is Wikipedia deciding how many times he should have shot intruders??   Why don't you just stop being what you're kNOWN for, Wiki, BIAS.  Just tell the facts.\n",
       "Name: 4128, dtype: object"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic.loc[4128, ['comment_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "comment_text    I noticed at the time that Tango reinserted the material you blocked me for adding to Giles Hattersley, but didn't think anything more of it, distracted as I was dealing with my own blocking. Now I've just seen elsewhere that you blocked him aswell. Subsequently reading the opinions at his talk page where he is unblocked after one hour, especially from other admins over what constitutes a personal attack, I am less than happy at how I got shafted over this incident, in which you have still failed to show I was intentionally attacking Giano - you seem to have absolutely no shame in levelling the same theory at Tango, an editor registered since Dec 2002, that you did to me, that the simple fact we are experienced editors that would have never seen a user's name linked in an article (I am still entirely unconvinced this is even true, especially for Wikipedia related text, but I have not researched it), we 'just should have known' it was considered a personal attack, blockable after no warning after making one edit/revert. Like I said, I would be willing to take it as 'ignorance is no defence' if this appeared in any policy text that I had just missed. And judging by his unblock request, he was not mistaken about what he was re-adding. So, quite clearly, you are attributing some malicious motive to me, that you aren't to Tango. Had I known of that discussion at the time, I have a good idea that things might have gone differently for me. It's not like I can do sod all about it now.\n",
       "Name: 4678, dtype: object"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic.loc[4678, ['comment_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "comment_text    \"\\n\\n Thanks! \\n\\nThanks for the barnstar! That was unexpected and certainly not necessary, but very much appreciated! Yeah, I guess the Wikicup has got my GA and DYK juices really flowing this month, lol, I appreciate your reviews, your support and your kind words! — ter Ka \"\n",
       "Name: 5046, dtype: object"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic.loc[5046, ['comment_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "comment_text    So, is it totally dead or we have a chance to see it sometime?\n",
       "Name: 5327, dtype: object"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic.loc[5327, ['comment_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "comment_text    Now all you need to do is press unblock. Please let me edit again. I won't do any of this ever again.\n",
       "Name: 5805, dtype: object"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic.loc[5805, ['comment_text']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
