{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from collections import Counter, Iterable\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, AlphaDropout, Dropout, LSTM, Bidirectional, TimeDistributed, InputLayer, Embedding, Conv1D, Input, Flatten, concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     /Users/macbookpro/nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('treebank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_sentences = nltk.corpus.treebank.tagged_sents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences, sentence_tags = [], [] \n",
    "for tagged_sentence in tagged_sentences:\n",
    "    sentence, tags = zip(*tagged_sentence)\n",
    "    sentences.append(sentence)\n",
    "    sentence_tags.append(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_train, sent_test, tag_train, tag_test = train_test_split(sentences, sentence_tags, test_size=0.2, \n",
    "                                                              random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = Counter()\n",
    "for sent in sent_train:\n",
    "    sent = [word.lower() for word in sent]\n",
    "    vocab.update(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_vocab = {word for word in vocab if vocab[word] > 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1679"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2id = {'PAD':0,'UNK':1}    \n",
    "for i,word in enumerate(filtered_vocab):\n",
    "      word2id[word] = i + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = {i:word for word, i in word2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1681"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(id2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag2id = {'UNK': 1, 'PAD':0}  \n",
    "for tags in tag_train:\n",
    "    for tag in tags:\n",
    "        if tag.lower() not in tag2id:\n",
    "            tag2id[tag.lower()] = len(tag2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2tag = {i:tag for tag, i in tag2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(id2tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data2ints(data, smth2id):\n",
    "    int_data = []\n",
    "    for seq in data:\n",
    "        int_seq = []\n",
    "        for i in seq:\n",
    "            try:\n",
    "                int_seq.append(smth2id[i.lower()])\n",
    "            except KeyError:\n",
    "                int_seq.append(smth2id['UNK'])\n",
    "  \n",
    "        int_data.append(int_seq)\n",
    "    return int_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ids, X_test_ids = data2ints(sent_train, word2id), data2ints(sent_test, word2id)\n",
    "y_train_ids, y_test_ids = data2ints(tag_train, tag2id), data2ints(tag_test, tag2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = max(len(x) for x in sent_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = pad_sequences(X_train_ids, maxlen=MAX_LEN, padding='post'), pad_sequences(X_test_ids, maxlen=MAX_LEN, padding='post')\n",
    "y_train_pad, y_test_pad = pad_sequences(y_train_ids, maxlen=MAX_LEN, padding='post'), pad_sequences(y_test_ids, maxlen=MAX_LEN, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3131, 128) (3131, 128) (783, 128) (783, 128)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train_pad.shape, X_test.shape, y_test_pad.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, y_test = to_categorical(y_train_pad, num_classes=len(tag2id)), to_categorical(y_test_pad, num_classes=len(tag2id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3131, 128, 48) (783, 128, 48)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_char = Counter()\n",
    "for sent in sent_train:\n",
    "    for word in sent:\n",
    "        word = [char.lower() for char in word]\n",
    "        by_char.update(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(by_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "char2id = {'PAD':0,'UNK':1}    \n",
    "for i,char in enumerate(by_char):\n",
    "      char2id[char] = i + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2char = {i:char for char, i in char2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ids_char = [data2ints(sent, char2id) for sent in sent_train]\n",
    "X_test_ids_char = [data2ints(sent, char2id) for sent in sent_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN_CHAR = max(max(len(word) for word in sent) for sent in X_train_ids_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_LEN_CHAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_padding(data, MAX_LEN, MAX_LEN_CHAR):\n",
    "    char_pad = np.zeros((len(data), MAX_LEN, MAX_LEN_CHAR))\n",
    "    for i, s in enumerate(data):\n",
    "        for j, word in enumerate(s):\n",
    "            for k, char in enumerate(word):\n",
    "                try:\n",
    "                    char_pad[i][j][k] = char\n",
    "                except:\n",
    "                    continue\n",
    "    return char_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_char = char_padding(X_train_ids_char, MAX_LEN, MAX_LEN_CHAR)\n",
    "X_test_char = char_padding(X_test_ids_char, MAX_LEN, MAX_LEN_CHAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3131, 128, 24) (3131, 128) (3131, 128, 48) (783, 128, 24) (783, 128) (783, 128, 48)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_char.shape,X_train.shape, y_train.shape, X_test_char.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_12 (InputLayer)           [(None, 128, 24)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_11 (InputLayer)           [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_19 (TimeDistri (None, 128, 24, 50)  2700        input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_10 (Embedding)        (None, 128, 70)      117670      input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_20 (TimeDistri (None, 128, 10, 40)  10040       time_distributed_19[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_9 (Bidirectional) (None, 128, 512)     669696      embedding_10[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_21 (TimeDistri (None, 128, 400)     0           time_distributed_20[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 128, 512)     0           bidirectional_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "alpha_dropout_4 (AlphaDropout)  (None, 128, 400)     0           time_distributed_21[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 128, 912)     0           dropout_5[0][0]                  \n",
      "                                                                 alpha_dropout_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_10 (Bidirectional (None, 128, 512)     2394112     concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_22 (TimeDistri (None, 128, 48)      24624       bidirectional_10[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 3,218,842\n",
      "Trainable params: 3,218,842\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_1 = Input(shape=(MAX_LEN,))\n",
    "embeddings_1 = Embedding(len(word2id), 70, mask_zero=True)(input_1)\n",
    "bilstm_1 = Bidirectional(LSTM(256, return_sequences=True))(embeddings_1)\n",
    "drop_1 = Dropout(0.2)(bilstm_1)\n",
    "\n",
    "input_2 = Input(shape=(MAX_LEN, MAX_LEN_CHAR,))\n",
    "embeddings_2 = TimeDistributed(Embedding(len(char2id), input_length=MAX_LEN_CHAR, output_dim=50))(input_2)\n",
    "conv_1 = TimeDistributed(Conv1D(kernel_size=5, filters=40, strides=2))(embeddings_2)\n",
    "flat_1 = TimeDistributed(Flatten())(conv_1)\n",
    "drop_2 = AlphaDropout(0.2)(flat_1)\n",
    "\n",
    "concat = concatenate([drop_1, drop_2])\n",
    "bilstm_2 = Bidirectional(LSTM(256, return_sequences=True))(concat)\n",
    "outputs = TimeDistributed(Dense(len(tag2id), activation='sigmoid'))(bilstm_2)\n",
    "\n",
    "model = tf.keras.Model(inputs=[input_1, input_2], outputs=outputs)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3131 samples, validate on 783 samples\n",
      "Epoch 1/32\n",
      "3131/3131 [==============================] - 442s 141ms/sample - loss: 0.6617 - acc: 0.1142 - val_loss: 0.6202 - val_acc: 0.1265\n",
      "Epoch 2/32\n",
      "3131/3131 [==============================] - 383s 122ms/sample - loss: 0.5958 - acc: 0.1278 - val_loss: 0.6078 - val_acc: 0.1360\n",
      "Epoch 3/32\n",
      "3131/3131 [==============================] - 332s 106ms/sample - loss: 0.5810 - acc: 0.1314 - val_loss: 0.5713 - val_acc: 0.1325\n",
      "Epoch 4/32\n",
      "3131/3131 [==============================] - 368s 117ms/sample - loss: 0.5348 - acc: 0.1307 - val_loss: 0.5319 - val_acc: 0.1324\n",
      "Epoch 5/32\n",
      "3131/3131 [==============================] - 254s 81ms/sample - loss: 0.5006 - acc: 0.1303 - val_loss: 0.5016 - val_acc: 0.1325\n",
      "Epoch 6/32\n",
      "3131/3131 [==============================] - 250s 80ms/sample - loss: 0.4523 - acc: 0.1304 - val_loss: 0.4372 - val_acc: 0.1325\n",
      "Epoch 7/32\n",
      "3131/3131 [==============================] - 236s 75ms/sample - loss: 0.3999 - acc: 0.1305 - val_loss: 0.3952 - val_acc: 0.1435\n",
      "Epoch 8/32\n",
      "3131/3131 [==============================] - 239s 76ms/sample - loss: 0.3159 - acc: 0.4366 - val_loss: 0.2767 - val_acc: 0.5835\n",
      "Epoch 9/32\n",
      "3131/3131 [==============================] - 239s 76ms/sample - loss: 0.2146 - acc: 0.6808 - val_loss: 0.2004 - val_acc: 0.7115\n",
      "Epoch 10/32\n",
      "3131/3131 [==============================] - 262s 84ms/sample - loss: 0.1572 - acc: 0.7701 - val_loss: 0.1580 - val_acc: 0.7770\n",
      "Epoch 11/32\n",
      "3131/3131 [==============================] - 319s 102ms/sample - loss: 0.1242 - acc: 0.8175 - val_loss: 0.1365 - val_acc: 0.8066\n",
      "Epoch 12/32\n",
      "3131/3131 [==============================] - 263s 84ms/sample - loss: 0.1033 - acc: 0.8497 - val_loss: 0.1184 - val_acc: 0.8339\n",
      "Epoch 13/32\n",
      "3131/3131 [==============================] - 312s 100ms/sample - loss: 0.0897 - acc: 0.8711 - val_loss: 0.1080 - val_acc: 0.8504\n",
      "Epoch 14/32\n",
      "3131/3131 [==============================] - 346s 111ms/sample - loss: 0.0802 - acc: 0.8848 - val_loss: 0.1063 - val_acc: 0.8516\n",
      "Epoch 15/32\n",
      "3131/3131 [==============================] - 311s 99ms/sample - loss: 0.0732 - acc: 0.8942 - val_loss: 0.0951 - val_acc: 0.8657\n",
      "Epoch 16/32\n",
      "3131/3131 [==============================] - 274s 87ms/sample - loss: 0.0678 - acc: 0.9002 - val_loss: 0.0894 - val_acc: 0.8759\n",
      "Epoch 17/32\n",
      "3131/3131 [==============================] - 283s 90ms/sample - loss: 0.0637 - acc: 0.9065 - val_loss: 0.0917 - val_acc: 0.8702\n",
      "Epoch 18/32\n",
      "3131/3131 [==============================] - 243s 77ms/sample - loss: 0.0599 - acc: 0.9112 - val_loss: 0.0800 - val_acc: 0.8866\n",
      "Epoch 19/32\n",
      "3131/3131 [==============================] - 360s 115ms/sample - loss: 0.0570 - acc: 0.9153 - val_loss: 0.0761 - val_acc: 0.8932\n",
      "Epoch 20/32\n",
      "3131/3131 [==============================] - 254s 81ms/sample - loss: 0.0538 - acc: 0.9201 - val_loss: 0.0745 - val_acc: 0.8944\n",
      "Epoch 21/32\n",
      "3131/3131 [==============================] - 284s 91ms/sample - loss: 0.0514 - acc: 0.9233 - val_loss: 0.0738 - val_acc: 0.8964\n",
      "Epoch 22/32\n",
      "3131/3131 [==============================] - 269s 86ms/sample - loss: 0.0484 - acc: 0.9277 - val_loss: 0.0735 - val_acc: 0.8954\n",
      "Epoch 23/32\n",
      "3131/3131 [==============================] - 273s 87ms/sample - loss: 0.0461 - acc: 0.9313 - val_loss: 0.0731 - val_acc: 0.8955\n",
      "Epoch 24/32\n",
      "3131/3131 [==============================] - 226s 72ms/sample - loss: 0.0444 - acc: 0.9338 - val_loss: 0.0690 - val_acc: 0.9020\n",
      "Epoch 25/32\n",
      "3131/3131 [==============================] - 211s 67ms/sample - loss: 0.0422 - acc: 0.9374 - val_loss: 0.0702 - val_acc: 0.9013\n",
      "Epoch 26/32\n",
      "3131/3131 [==============================] - 205s 65ms/sample - loss: 0.0400 - acc: 0.9411 - val_loss: 0.0648 - val_acc: 0.9086\n",
      "Epoch 27/32\n",
      "3131/3131 [==============================] - 208s 66ms/sample - loss: 0.0384 - acc: 0.9433 - val_loss: 0.0647 - val_acc: 0.9073\n",
      "Epoch 28/32\n",
      "3131/3131 [==============================] - 197s 63ms/sample - loss: 0.0362 - acc: 0.9469 - val_loss: 0.0657 - val_acc: 0.9046\n",
      "Epoch 29/32\n",
      "3131/3131 [==============================] - 248s 79ms/sample - loss: 0.0344 - acc: 0.9490 - val_loss: 0.0635 - val_acc: 0.9098\n",
      "Epoch 30/32\n",
      "3131/3131 [==============================] - 209s 67ms/sample - loss: 0.0326 - acc: 0.9518 - val_loss: 0.0626 - val_acc: 0.9109\n",
      "Epoch 31/32\n",
      "3131/3131 [==============================] - 234s 75ms/sample - loss: 0.0311 - acc: 0.9540 - val_loss: 0.0609 - val_acc: 0.9139\n",
      "Epoch 32/32\n",
      "3131/3131 [==============================] - 219s 70ms/sample - loss: 0.0297 - acc: 0.9567 - val_loss: 0.0606 - val_acc: 0.9141\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1549c9e50>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([X_train, X_train_char], y_train, validation_data=([X_test, X_test_char], y_test), batch_size=128, epochs=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_tag(sentence):\n",
    "    sentence_len = len(sentence)\n",
    "    sent_ids = data2ints([sentence], word2id)\n",
    "    sentence_pad = pad_sequences(sent_ids, maxlen=MAX_LEN, padding='post')\n",
    "    char_sent = [[list(word) for word in s] for s in [sentence]]\n",
    "    char_sent_ids = [data2ints(sent, char2id) for sent in char_sent]\n",
    "    padded_chars = char_padding(char_sent_ids, MAX_LEN, MAX_LEN_CHAR)\n",
    "    tags_ids = np.argmax(model.predict([sentence_pad, padded_chars]), axis=2).tolist()[0][:sentence_len]\n",
    "    tags = [id2tag[ind] for ind in tags_ids]  \n",
    "    return [(word, tag) for word, tag in zip(sentence, tags)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Composer', 'nnp'),\n",
       " ('Marc', 'nnp'),\n",
       " ('Marder', 'nnp'),\n",
       " (',', ','),\n",
       " ('a', 'dt'),\n",
       " ('college', 'nn'),\n",
       " ('friend', 'nn'),\n",
       " ('of', 'in'),\n",
       " ('Mr.', 'nnp'),\n",
       " ('Lane', 'nnp'),\n",
       " (\"'s\", 'pos'),\n",
       " ('who', 'wp'),\n",
       " ('*T*-66', '-none-'),\n",
       " ('earns', 'vbz'),\n",
       " ('his', 'prp$'),\n",
       " ('living', 'nns'),\n",
       " ('*-1', '-none-'),\n",
       " ('playing', 'vbg'),\n",
       " ('the', 'dt'),\n",
       " ('double', 'jj'),\n",
       " ('bass', 'nn'),\n",
       " ('in', 'in'),\n",
       " ('classical', 'nnp'),\n",
       " ('music', 'nnp'),\n",
       " ('ensembles', 'nns'),\n",
       " (',', ','),\n",
       " ('has', 'vbz'),\n",
       " ('prepared', 'vbn'),\n",
       " ('an', 'dt'),\n",
       " ('exciting', 'nn'),\n",
       " (',', ','),\n",
       " ('eclectic', 'jj'),\n",
       " ('score', 'nn'),\n",
       " ('that', 'wdt'),\n",
       " ('*T*-67', '-none-'),\n",
       " ('tells', 'vbz'),\n",
       " ('you', 'prp'),\n",
       " ('what', 'wp'),\n",
       " ('the', 'dt'),\n",
       " ('characters', 'nns'),\n",
       " ('are', 'vbp'),\n",
       " ('thinking', 'vbg'),\n",
       " ('*T*-2', '-none-'),\n",
       " ('and', 'cc'),\n",
       " ('feeling', 'nns'),\n",
       " ('*T*-2', '-none-'),\n",
       " ('far', 'rb'),\n",
       " ('more', 'rbr'),\n",
       " ('precisely', 'jj'),\n",
       " ('than', 'in'),\n",
       " ('intertitles', 'nns'),\n",
       " (',', ','),\n",
       " ('or', 'cc'),\n",
       " ('even', 'rb'),\n",
       " ('words', 'nns'),\n",
       " (',', ','),\n",
       " ('would', 'md'),\n",
       " ('*?*', '-none-'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_tag(sent_train[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
