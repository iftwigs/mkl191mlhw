{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbookpro/miniconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.scorer module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/macbookpro/miniconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.feature_selection.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_selection. Anything that cannot be imported from sklearn.feature_selection is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import eli5\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import *\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "count_vect = CountVectorizer(max_features=1000, min_df=0.01, max_df=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['talk.religion.misc', 'sci.crypt', 'misc.forsale', 'comp.sys.mac.hardware']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "twenty_train = fetch_20newsgroups(subset='train', categories=categories, shuffle=True)\n",
    "twenty_test = fetch_20newsgroups(subset='test', categories=categories, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'From: tcmay@netcom.com (Timothy C. May)\\nSubject: Re: Once tapped, your code is no good any more.\\nOrganization: NETCOM On-line Communication Services (408 241-9760 guest)\\nX-Newsreader: Tin 1.1 PL5\\nDistribution: na\\nLines: 51\\n\\nBrad Templeton (brad@clarinet.com) wrote:\\n: It occurs to me that if they get a wiretap order on you, and the escrow\\n: houses release your code to the cops, your code is now no longer secure.\\n: \\n: It\\'s in the hands of cops, and while I am sure most of the time they are\\n: good, their security will not be as good as the escrow houses.\\n: \\n: \\n: What this effectively means is that if they perform a wiretap on you,\\n: at the end of the wiretap, they should be obligated to inform you that\\n: a tap was performed, and replace (for free) the clipper chip in your\\n: cellular phone so that it is once again a code known only to the\\n: escrow houses.\\n\\nGetting the court order to reveal the key *also* makes decipherable\\nall *past* conversations (which may be on tape, or disk, or whatver),\\nas I understand the proposal. I could be wrong, but I\\'ve seen no\\nmention of \"session keys\" being the escrowed entities.\\n\\nAs the EFF noted, this raises further issues about the fruits of one\\nbust leading to incrimination in other areas.\\n\\nBut is it any worse than the current unsecure system? It becomes much\\nworse, of course, if the government then uses this \"Clinton Clipper\"\\nto argue for restrictions on unapproved encryption. (This is the main\\nconcern of most of us, I think. The camel\\'s nose in the tent, etc.)\\n\\nAnd it may also become much worse if the ostensible security is\\nincreased, thus allowing greater access to \"central office\" records by\\nthe government (the conversations being encrypted, who will object to\\nletting the government have access to them, perhaps even automatically\\narchiving large fractions...). This was one of the main objections to\\nthe S.266 proposal, that it would force telecom suppliers to provide\\neasy access for the government.\\n\\nOne the government has had access to months or years of your encrypted\\nconversations, now all it takes is one misstep, one violation that\\ngets them the paperwork needed to decrypt *all* of them!\\n\\nDo we want anyone to have this kind of power?\\n\\n-Tim May, whose sig block may get him busted in the New Regime\\n\\n-- \\n..........................................................................\\nTimothy C. May         | Crypto Anarchy: encryption, digital money,  \\ntcmay@netcom.com       | anonymous networks, digital pseudonyms, zero\\n408-688-5409           | knowledge, reputations, information markets, \\nW.A.S.T.E.: Aptos, CA  | black markets, collapse of governments.\\nHigher Power: 2^756839 | Public Key: PGP and MailSafe available.\\n\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_train.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Distribution: world\\nFrom: Tony_Sullivan@mcontent.apana.org.au\\nOrganization: MacContent BBS, Doncaster, Victoria, Australia\\nReturn-Receipt-To: Tony_Sullivan@mcontent.apana.org.au\\nSubject: Re: DeskWriter Drivers 3.1 -- How to install ?\\nLines: 16\\n\\nCan someone tell me which of the files that come with DW-3.1 go where\\nand for what purpose?  What can be left out, for instance, if\\nyou don't want to do background printing?\\n\\nAs far as I can remember, all you need to do to get your Deskwriter up and\\nprinting using the 3.1 driver is to drag the driver itself (either serial or\\nappletalk depending on your needs) to the system folder. You don't need the\\nfonts or anything else if all you want is straight forward, bare bones, basic\\nprinting....I don't have anything else installed and can still print on a\\nDeskwriter using sys7.1 and HP driver 3.1\\nTony\\n***************************************************************************\\n The views expressed in this posting those of the individual author only. \\n[BBS Number:(613) 848-1346      MacContent is Victoria√ïs first Iconic BBS!]\\n***************************************************************************\\n\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_test.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = count_vect.fit_transform(twenty_train.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2135x1000 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 134527 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = count_vect.transform(twenty_test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bestparams(model, grid, folds, data, classes):\n",
    "    grid_search = GridSearchCV(model, param_grid=grid, cv=folds, scoring='f1_macro')\n",
    "    grid_search.fit(data, classes) \n",
    "    return grid_search.best_score_, grid_search.best_params_, grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fold = 10\n",
    "folds = KFold(n_splits=n_fold, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [LogisticRegression(), LinearSVC(), SGDClassifier()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "grids = [{'class_weight' : ['balanced', None], 'C': [1, 2], 'max_iter': [100, 150]},\n",
    "        {'loss' : ['hinge', 'squared_hinge'], 'intercept_scaling' : [1, 2]},\n",
    "        {'alpha': [0.0001, 0.05, 0.1], 'max_iter': [100, 200]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosenmodels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainscores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score is 0.9354025292320112\n",
      "Best parameters are {'C': 1, 'class_weight': 'balanced', 'max_iter': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbookpro/miniconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score is 0.920787440458526\n",
      "Best parameters are {'intercept_scaling': 1, 'loss': 'hinge'}\n",
      "Best score is 0.9468505220519082\n",
      "Best parameters are {'alpha': 0.05, 'max_iter': 200}\n"
     ]
    }
   ],
   "source": [
    " for i in range(3):\n",
    "    best_score, best_params, best_estimator = bestparams(models[i], grids[i], folds, X_train, twenty_train.target)\n",
    "    print('Best score is {}'.format(best_score))\n",
    "    print('Best parameters are {}'.format(best_params))\n",
    "    trainscores.append(best_score)\n",
    "    chosenmodels.append(best_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg train: 1.0\n",
      "logreg test: 0.9030155991223628\n"
     ]
    }
   ],
   "source": [
    "lr = chosenmodels[0].fit(X_train, twenty_train.target)\n",
    "train_preds_lr = lr.predict(X_train)\n",
    "test_preds_lr = lr.predict(X_test)\n",
    "print('logreg train: {}'.format(f1_score(twenty_train.target, train_preds_lr, average='macro')))\n",
    "print('logreg test: {}'.format(f1_score(twenty_test.target,test_preds_lr, average='macro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg train: 1.0\n",
      "logreg test: 0.88654588952225\n"
     ]
    }
   ],
   "source": [
    "svc = chosenmodels[1].fit(X_train, twenty_train.target)\n",
    "train_preds_svc = svc.predict(X_train)\n",
    "test_preds_svc = svc.predict(X_test)\n",
    "print('logreg train: {}'.format(f1_score(twenty_train.target, train_preds_svc, average='macro')))\n",
    "print('logreg test: {}'.format(f1_score(twenty_test.target,test_preds_svc, average='macro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg train: 0.9815896106223347\n",
      "logreg test: 0.9183836710615192\n"
     ]
    }
   ],
   "source": [
    "sgd = chosenmodels[2].fit(X_train, twenty_train.target)\n",
    "train_preds_sgd = sgd.predict(X_train)\n",
    "test_preds_sgd = sgd.predict(X_test)\n",
    "print('logreg train: {}'.format(f1_score(twenty_train.target, train_preds_sgd, average='macro')))\n",
    "print('logreg test: {}'.format(f1_score(twenty_test.target,test_preds_sgd, average='macro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_features(model, n):\n",
    "    index_to_word = {v:k for k,v in count_vect.vocabulary_.items()}\n",
    "    eli = eli5.formatters.as_dataframe.explain_weights_df(model)\n",
    "    compsysmachardware = eli[eli['target']==0]\n",
    "    miscforsale = eli[eli['target']==1]\n",
    "    scicrypt = eli[eli['target']==2]\n",
    "    talkreligionmisc = eli[eli['target']==3]\n",
    "    print(n, 'most significant compsysmachardware features: ')\n",
    "    for element in compsysmachardware.feature[:n]:\n",
    "        if element != '<BIAS>':\n",
    "            feature = element.strip('x')\n",
    "            print(index_to_word[int(feature)])\n",
    "    print(n, 'most significant miscforsale features: ')\n",
    "    for element in miscforsale.feature[:n]:\n",
    "        if element != '<BIAS>':\n",
    "            feature = element.strip('x')\n",
    "            print(index_to_word[int(feature)])\n",
    "    print(n, 'most significant scicrypt features: ')\n",
    "    for element in scicrypt.feature[:n]:\n",
    "        if element != '<BIAS>':\n",
    "            feature = element.strip('x')\n",
    "            print(index_to_word[int(feature)])\n",
    "    print(n, 'most significant talkreligionmisc features: ')\n",
    "    for element in talkreligionmisc.feature[:n]:\n",
    "        if element != '<BIAS>':\n",
    "            feature = element.strip('x')\n",
    "            print(index_to_word[int(feature)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 most significant compsysmachardware features: \n",
      "mac\n",
      "apple\n",
      "quadra\n",
      "comp\n",
      "duo\n",
      "macs\n",
      "buy\n",
      "hardware\n",
      "powerbook\n",
      "simms\n",
      "10 most significant miscforsale features: \n",
      "sale\n",
      "forsale\n",
      "wanted\n",
      "sell\n",
      "condition\n",
      "offer\n",
      "trade\n",
      "commercial\n",
      "interested\n",
      "10 most significant scicrypt features: \n",
      "clipper\n",
      "encryption\n",
      "key\n",
      "security\n",
      "crypto\n",
      "netcom\n",
      "nsa\n",
      "gtoal\n",
      "code\n",
      "chip\n",
      "10 most significant talkreligionmisc features: \n",
      "god\n",
      "christian\n",
      "koresh\n",
      "bible\n",
      "utexas\n",
      "frank\n",
      "religion\n",
      "virginia\n",
      "sandvik\n",
      "morality\n"
     ]
    }
   ],
   "source": [
    "analyze_features(lr, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 most significant compsysmachardware features: \n",
      "comp\n",
      "macs\n",
      "duo\n",
      "buy\n",
      "quadra\n",
      "5 most significant miscforsale features: \n",
      "forsale\n",
      "sale\n",
      "sell\n",
      "wanted\n",
      "trade\n",
      "5 most significant scicrypt features: \n",
      "nsa\n",
      "clipper\n",
      "crypto\n",
      "security\n",
      "key\n",
      "5 most significant talkreligionmisc features: \n",
      "god\n",
      "koresh\n",
      "christian\n",
      "utexas\n",
      "never\n"
     ]
    }
   ],
   "source": [
    "analyze_features(svc, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 most significant compsysmachardware features: \n",
      "mac\n",
      "apple\n",
      "quadra\n",
      "powerbook\n",
      "thanks\n",
      "5 most significant miscforsale features: \n",
      "sale\n",
      "wanted\n",
      "forsale\n",
      "offer\n",
      "sell\n",
      "5 most significant scicrypt features: \n",
      "clipper\n",
      "encryption\n",
      "security\n",
      "key\n",
      "code\n",
      "5 most significant talkreligionmisc features: \n",
      "god\n",
      "christian\n",
      "bible\n",
      "religion\n",
      "koresh\n"
     ]
    }
   ],
   "source": [
    "analyze_features(sgd, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ö–∞–∫–∏—Ö-—Ç–æ —è–≤–Ω—ã—Ö –æ—à–∏–±–æ–∫ –Ω–µ –≤–∏–¥–Ω–æ, –∏–∑ —Å—Ç—Ä–∞–Ω–Ω–æ—Å—Ç–µ–π –º–æ–∂–Ω–æ –æ—Ç–º–µ—Ç–∏—Ç—å koresh –≤ talkreligionmisc –∏ thanks –≤ compsysmachardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_count_vect = CountVectorizer(max_features=1000, min_df=0.009, max_df=0.39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = new_count_vect.fit_transform(twenty_train.data)\n",
    "X_test = new_count_vect.transform(twenty_test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosenmodels2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainscores2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score is 0.9354025292320112\n",
      "Best parameters are {'C': 1, 'class_weight': 'balanced', 'max_iter': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbookpro/miniconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score is 0.9214645940907962\n",
      "Best parameters are {'intercept_scaling': 2, 'loss': 'hinge'}\n",
      "Best score is 0.9466082056212308\n",
      "Best parameters are {'alpha': 0.05, 'max_iter': 100}\n"
     ]
    }
   ],
   "source": [
    " for i in range(3):\n",
    "    best_score, best_params, best_estimator = bestparams(models[i], grids[i], folds, X_train, twenty_train.target)\n",
    "    print('Best score is {}'.format(best_score))\n",
    "    print('Best parameters are {}'.format(best_params))\n",
    "    trainscores2.append(best_score)\n",
    "    chosenmodels2.append(best_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg train: 1.0\n",
      "logreg test: 0.9044516043814963\n"
     ]
    }
   ],
   "source": [
    "lr = chosenmodels[0].fit(X_train, twenty_train.target)\n",
    "train_preds_lr = lr.predict(X_train)\n",
    "test_preds_lr = lr.predict(X_test)\n",
    "print('logreg train: {}'.format(f1_score(twenty_train.target, train_preds_lr, average='macro')))\n",
    "print('logreg test: {}'.format(f1_score(twenty_test.target,test_preds_lr, average='macro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg train: 1.0\n",
      "logreg test: 0.8871886686216324\n"
     ]
    }
   ],
   "source": [
    "svc = chosenmodels[1].fit(X_train, twenty_train.target)\n",
    "train_preds_svc = svc.predict(X_train)\n",
    "test_preds_svc = svc.predict(X_test)\n",
    "print('logreg train: {}'.format(f1_score(twenty_train.target, train_preds_svc, average='macro')))\n",
    "print('logreg test: {}'.format(f1_score(twenty_test.target,test_preds_svc, average='macro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg train: 0.9825556241456646\n",
      "logreg test: 0.9203212954013573\n"
     ]
    }
   ],
   "source": [
    "sgd = chosenmodels[2].fit(X_train, twenty_train.target)\n",
    "train_preds_sgd = sgd.predict(X_train)\n",
    "test_preds_sgd = sgd.predict(X_test)\n",
    "print('logreg train: {}'.format(f1_score(twenty_train.target, train_preds_sgd, average='macro')))\n",
    "print('logreg test: {}'.format(f1_score(twenty_test.target,test_preds_sgd, average='macro')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–°–∏–ª—å–Ω–æ –∏–∑–º–µ–Ω–∏—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –Ω–µ —É–¥–∞–ª–æ—Å—å. –ù–æ —á—É—Ç—å-—á—É—Ç—å —É–¥–∞–ª–æ—Å—å."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
